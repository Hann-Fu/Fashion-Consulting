{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa8f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns, warnings\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, StackingClassifier\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge, BayesianRidge, LassoLarsIC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, OneHotEncoder, TargetEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from fastcore.transform import Transform\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "import lightgbm as lgb, xgboost as xgb\n",
    "\n",
    "# Filter useless warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_path = '/Users/fuhan/Desktop/Kaggle/house-prices-advanced-regression-techniques/train.csv'\n",
    "test_path = '/Users/fuhan/Desktop/Kaggle/house-prices-advanced-regression-techniques/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c949f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(df):\n",
    "    df[\"PoolQC\"] = df[\"PoolQC\"].fillna(\"None\")\n",
    "    df[\"MiscFeature\"] = df[\"MiscFeature\"].fillna(\"None\")\n",
    "    df[\"Alley\"] = df[\"Alley\"].fillna(\"None\")\n",
    "    df[\"Fence\"] = df[\"Fence\"].fillna(\"None\")\n",
    "    df[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna(\"None\")\n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "        df[col] = df[col].fillna('None')\n",
    "\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        df[col] = df[col].fillna(0)\n",
    "    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "        df[col] = df[col].fillna('None')\n",
    "    df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\n",
    "    df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0)\n",
    "    df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\n",
    "    df[\"MasVnrArea\"] = df[\"MasVnrArea\"].fillna(0)\n",
    "    df['MSZoning'] = df['MSZoning'].fillna(df['MSZoning'].mode()[0])\n",
    "    df.drop(['Utilities'], axis=1,inplace=True)\n",
    "    df[\"Functional\"] = df[\"Functional\"].fillna(\"Typ\")\n",
    "    df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "    df['KitchenQual'] = df['KitchenQual'].fillna(df['KitchenQual'].mode()[0])\n",
    "    df['Exterior1st'] = df['Exterior1st'].fillna('Other')\n",
    "    df['Exterior2nd'] = df['Exterior2nd'].fillna('Other')\n",
    "    df['SaleType'] = df['SaleType'].fillna(df['SaleType'].mode()[0])\n",
    "    df['MSSubClass'] = df['MSSubClass'].fillna(\"None\")\n",
    "    df[\"LotFrontage\"] = df.groupby(\"Neighborhood\")['LotFrontage'].transform(\n",
    "                                lambda x: x.fillna(x.median()))\n",
    "    \n",
    "def ordinal_encoder(feature_t_list, df_org, df_ed):\n",
    "    Contrast = []\n",
    "    df_con = df_org.copy(deep=True)\n",
    "    for item in feature_t_list:\n",
    "        df_temp = df_con.groupby(item)['SalePrice'].mean().reset_index()\n",
    "        df_temp = df_temp.sort_values(by = 'SalePrice', ascending = True)\n",
    "        df_temp['Rank'] = df_temp['SalePrice'].rank().astype(int)\n",
    "        \n",
    "        # Combine the original feature and rank\n",
    "        correlation_list = [[i,j] for i,j in zip(df_temp[item],df_temp['Rank'])]        \n",
    "        Contrast.append([[item,df_temp[item].nunique()],correlation_list])\n",
    "        \n",
    "    for i in Contrast:\n",
    "        for value in i[1]:\n",
    "            df_ed.loc[:, i[0][0]] = df_ed[i[0][0]].replace(value[0], int(value[1]))\n",
    "\n",
    "    return Contrast\n",
    "\n",
    "def feature_create(df):\n",
    "    df['LivingQual'] = 4*df['HeatingQC'] + 5*df['KitchenQual']\n",
    "    df['RoomNum'] = df['TotRmsAbvGrd'] + df['FullBath'] + 0.5*df['HalfBath'] + df['KitchenAbvGr']\n",
    "    df['UsedYears'] = 7*(2010-df['YearRemodAdd'])+4*(2010-df['YearBuilt'])\n",
    "    df['GarageYrUsed'] = 2010-df['GarageYrBlt']\n",
    "    df['GarageQualArea'] = df['GarageFinish']*df['GarageCond']*df['GarageArea']\n",
    "    df['InteriorArea'] = 0.2*df['BsmtCond']*df['TotalBsmtSF']+df['OverallQual']*df['GrLivArea']\n",
    "    df['ExteriorArea'] = df['LotArea']-df['1stFlrSF']\n",
    "    df['Penalty'] = df['OverallQual']*df['LowQualFinSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307b59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "one_hot = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig',\n",
    "           'Condition1', 'Condition2', 'BldgType',\n",
    "           'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n",
    "           'MasVnrType', 'Foundation', 'BsmtExposure', 'Heating',\n",
    "           'CentralAir', 'Electrical', 'Functional', 'Neighborhood',\n",
    "           'GarageType', 'PavedDrive',  'MiscFeature', 'SaleType',\n",
    "           'SaleCondition']\n",
    "\n",
    "# Ordinal_encode based on target\n",
    "ordinal_encode = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtFinType1',\n",
    "                  'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu','GarageQual', \n",
    "                  'GarageCond', 'PoolQC', 'Fence', 'GarageFinish',\n",
    "                  'Alley', 'LandSlope']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ccea6",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3404d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_test_id = df_test['Id']\n",
    "\n",
    "# Concate train and test dataset\n",
    "df = pd.concat([df_train,df_test], axis=0, ignore_index=True)\n",
    "df = df.drop('Id', axis=1)\n",
    "train_size = df_train.shape[0]\n",
    "\n",
    "# Check the datatype\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "numerical_columns = df.select_dtypes(exclude=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb9adf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87c9d24",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1c3520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing value\n",
    "impute_missing(df)\n",
    "impute_missing(df_train)\n",
    "\n",
    "# Categorical Feature One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=one_hot, drop_first=True)\n",
    "# Ordinal_encode\n",
    "contrast = ordinal_encoder(ordinal_encode,df_train,df)\n",
    "\n",
    "# Skewness Fixing\n",
    "skewed_feats = df[numerical_columns].apply(lambda x: skew(x.dropna()))\n",
    "skewness = skewed_feats[skewed_feats>1]\n",
    "skewness_tran = ['MSSubClass', 'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1',\n",
    "               'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    "               'BsmtHalfBath', 'KitchenAbvGr', 'WoodDeckSF', 'OpenPorchSF',\n",
    "               'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n",
    "skewed_features = skewness_tran\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    df[feat] += 1\n",
    "    df[feat] = boxcox1p(df[feat], lam)\n",
    "    \n",
    "\n",
    "# Feature Engineering\n",
    "feature_create(df)\n",
    "    \n",
    "\n",
    "# Split back to train and test\n",
    "df_train = df[:train_size]\n",
    "df_test = df[train_size:]\n",
    "\n",
    "X = df_train.drop('SalePrice', axis=1)\n",
    "y = df_train['SalePrice']\n",
    "\n",
    "# y log transform\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c52e6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd18f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588098c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------Model Initialize--------------------------\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = make_pipeline(RobustScaler(), KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5))\n",
    "RF = RandomForestRegressor()\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,verbose=-1)\n",
    "\n",
    "# ----------------------Cross Validation--------------------------\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X)\n",
    "    rmlse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmlse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_box = [['lasso',lasso], \n",
    "             ['ENet',ENet], \n",
    "             ['KRR',KRR], \n",
    "             ['RF',RF], \n",
    "             ['GBoost',GBoost], \n",
    "             ['model_xgb',model_xgb], \n",
    "             ['model_lgb',model_lgb]]\n",
    "model_box = [lasso, ENet, KRR, RF, GBoost, model_xgb, model_lgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2373bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "Score: 0.1281 (0.0159)\n",
      "\n",
      "ENet\n",
      "Score: 0.1283 (0.0159)\n",
      "\n",
      "KRR\n",
      "Score: 0.1312 (0.0131)\n",
      "\n",
      "RF\n",
      "Score: 0.1446 (0.0101)\n",
      "\n",
      "GBoost\n",
      "Score: 0.1246 (0.0118)\n",
      "\n",
      "model_xgb\n",
      "Score: 0.1280 (0.0099)\n",
      "\n",
      "model_lgb\n",
      "Score: 0.1252 (0.0098)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_name_box:\n",
    "    score = rmsle_cv(model[1])\n",
    "    print(model[0])\n",
    "    print(\"Score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5062770",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dafef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.1210 (0.0120)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (lasso, ENet, GBoost, model_xgb, model_lgb))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a187ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.1298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "base_models = [\n",
    "    ('ENet', ENet),\n",
    "    ('GBoost', GBoost),\n",
    "    ('model_lgb', model_lgb)\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the meta-learner (Gradient Boosting Classifier)\n",
    "meta_model = lasso\n",
    "stack_reg = StackingRegressor(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stack_reg.fit(X_train, y_train)\n",
    "y_pred = stack_reg.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34e6af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Regressor score: 0.1268 (0.0218)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Simpler approach using StackingRegressor\n",
    "# Assuming lasso, ENet, GBoost, model_xgb, model_lgb are regressors\n",
    "stacking_regressor = StackingRegressor(estimators=[\n",
    "    ('lasso', lasso),\n",
    "    ('ENet', ENet),\n",
    "    ('GBoost', GBoost),\n",
    "    ('model_xgb', model_xgb),\n",
    "    ('model_lgb', model_lgb)\n",
    "])\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return rmse\n",
    "\n",
    "score = rmsle_cv(stacking_regressor)\n",
    "print(\"Stacking Regressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c1c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor (Averaging) score: 0.1260 (0.0202)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Simpler approach using VotingRegressor for averaging predictions\n",
    "# Assuming lasso, ENet, GBoost, model_xgb, model_lgb are regressors\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lasso', lasso),\n",
    "    ('ENet', ENet),\n",
    "    ('GBoost', GBoost),\n",
    "    ('model_xgb', model_xgb),\n",
    "    ('model_lgb', model_lgb)\n",
    "])\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return rmse\n",
    "\n",
    "score = rmsle_cv(voting_regressor)\n",
    "print(\"Voting Regressor (Averaging) score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab6b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model emmbeded\n",
    "final_model = voting_regressor.fit(X,y)\n",
    "# Drop the target\n",
    "# df_test = df_test.drop('SalePrice',axis=1)\n",
    "# Get the result\n",
    "result = final_model.predict(df_test)\n",
    "# Transform back to og\n",
    "result_org = np.expm1(result)\n",
    "\n",
    "# Out put the sub file\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = df_test_id\n",
    "sub['SalePrice'] = result_org\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ef6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model stack\n",
    "final_model = stacking_regressor.fit(X,y)\n",
    "# Drop the target\n",
    "# df_test = df_test.drop('SalePrice',axis=1)\n",
    "# Get the result\n",
    "result = final_model.predict(df_test)\n",
    "# Transform back to og\n",
    "result_org = np.expm1(result)\n",
    "\n",
    "# Out put the sub file\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = df_test_id\n",
    "sub['SalePrice'] = result_org\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363ee81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model lassao\n",
    "final_model = lasso.fit(X,y)\n",
    "# Drop the target\n",
    "# df_test = df_test.drop('SalePrice',axis=1)\n",
    "# Get the result\n",
    "result = final_model.predict(df_test)\n",
    "# Transform back to og\n",
    "result_org = np.expm1(result)\n",
    "\n",
    "# Out put the sub file\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = df_test_id\n",
    "sub['SalePrice'] = result_org\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
